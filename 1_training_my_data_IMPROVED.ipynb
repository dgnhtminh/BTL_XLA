{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a9bad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot set 'randint' attribute of immutable type 'numpy.random.mtrand.RandomState'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Replace both np.random.randint and RandomState.randint\u001b[39;00m\n\u001b[0;32m     78\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint \u001b[38;5;241m=\u001b[39m _safe_randint\n\u001b[1;32m---> 79\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState\u001b[38;5;241m.\u001b[39mrandint \u001b[38;5;241m=\u001b[39m _safe_RandomState_randint\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Compatibility patch loaded (NumPy 2.x + Python 3.13)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot set 'randint' attribute of immutable type 'numpy.random.mtrand.RandomState'"
     ]
    }
   ],
   "source": [
    "# === CRITICAL: Python 3.13 + NumPy 2.x Compatibility Patch ===\n",
    "import random\n",
    "import numpy as np\n",
    "from unittest.mock import patch\n",
    "\n",
    "def _patched_choice(population, k, replace=True):\n",
    "    try:\n",
    "        state = random.getstate()\n",
    "        random.seed(np.random.randint(0, 2**31 - 1))\n",
    "        if replace:\n",
    "            return random.choices(population, k=k)\n",
    "        else:\n",
    "            return random.sample(population, k=k)\n",
    "    finally:\n",
    "        random.setstate(state)\n",
    "\n",
    "# Monkey patch NumPy's random functions to handle int32 overflow and dtype issues\n",
    "_original_randint = np.random.randint\n",
    "_original_RandomState_randint = np.random.RandomState.randint\n",
    "\n",
    "def _safe_randint(low, high=None, size=None, dtype=None):\n",
    "    \"\"\"Safe randint that handles int32 overflow and dtype issues\"\"\"\n",
    "    # Handle dtype parameter - convert to proper integer type\n",
    "    if dtype is not None:\n",
    "        if np.issubdtype(dtype, np.floating):\n",
    "            dtype = np.int32  # Convert float dtype to int32\n",
    "        elif not np.issubdtype(dtype, np.integer):\n",
    "            dtype = np.int32\n",
    "    \n",
    "    if high is None:\n",
    "        high = low\n",
    "        low = 0\n",
    "    \n",
    "    # Ensure values fit in int32 range\n",
    "    int32_max = 2**31 - 1\n",
    "    int32_min = -(2**31)\n",
    "    \n",
    "    if isinstance(high, (int, np.integer)) and high > int32_max:\n",
    "        high = int32_max\n",
    "    if isinstance(low, (int, np.integer)) and low < int32_min:\n",
    "        low = 0\n",
    "    \n",
    "    # Ensure low < high\n",
    "    if low >= high:\n",
    "        high = low + 1\n",
    "    \n",
    "    return _original_randint(low, high, size=size, dtype=dtype)\n",
    "\n",
    "def _safe_RandomState_randint(self, low, high=None, size=None, dtype=None):\n",
    "    \"\"\"Safe RandomState.randint that handles dtype issues\"\"\"\n",
    "    # Handle dtype parameter\n",
    "    if dtype is not None:\n",
    "        if np.issubdtype(dtype, np.floating):\n",
    "            dtype = np.int32\n",
    "        elif not np.issubdtype(dtype, np.integer):\n",
    "            dtype = np.int32\n",
    "    \n",
    "    if high is None:\n",
    "        high = low\n",
    "        low = 0\n",
    "    \n",
    "    # Ensure values fit in int32 range\n",
    "    int32_max = 2**31 - 1\n",
    "    int32_min = -(2**31)\n",
    "    \n",
    "    if isinstance(high, (int, np.integer)) and high > int32_max:\n",
    "        high = int32_max\n",
    "    if isinstance(low, (int, np.integer)) and low < int32_min:\n",
    "        low = 0\n",
    "    \n",
    "    # Ensure low < high\n",
    "    if low >= high:\n",
    "        high = low + 1\n",
    "    \n",
    "    return _original_RandomState_randint(self, low, high, size=size, dtype=dtype)\n",
    "\n",
    "# Replace both np.random.randint and RandomState.randint\n",
    "np.random.randint = _safe_randint\n",
    "np.random.RandomState.randint = _safe_RandomState_randint\n",
    "\n",
    "print(\"‚úÖ Compatibility patch loaded (NumPy 2.x + Python 3.13)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3c17d",
   "metadata": {},
   "source": [
    "## 1. Import v√† Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac11db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Applied compatibility patch\n",
      "TensorFlow: 2.20.0\n",
      "GPU: []\n",
      "TensorFlow: 2.20.0\n",
      "GPU: []\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D\n",
    "\n",
    "# Apply patch\n",
    "import csbdeep.utils.utils\n",
    "csbdeep.utils.utils.choice = _patched_choice\n",
    "print(\"‚úÖ Applied compatibility patch\")\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "# Check GPU\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fb9b2",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd769703",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_train_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;28mstr\u001b[39m(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      4\u001b[0m Y_train_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;28mstr\u001b[39m(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = Path('my_dataset')\n",
    "\n",
    "X_train_files = sorted(glob(str(data_dir / 'train' / 'images' / '*')))\n",
    "Y_train_files = sorted(glob(str(data_dir / 'train' / 'masks' / '*')))\n",
    "X_val_files = sorted(glob(str(data_dir / 'val' / 'images' / '*')))\n",
    "Y_val_files = sorted(glob(str(data_dir / 'val' / 'masks' / '*')))\n",
    "\n",
    "print(f\"üìä Dataset size:\")\n",
    "print(f\"   Training: {len(X_train_files)} images\")\n",
    "print(f\"   Validation: {len(X_val_files)} images\")\n",
    "print(f\"   Total: {len(X_train_files) + len(X_val_files)} images\")\n",
    "\n",
    "# Ki·ªÉm tra\n",
    "assert len(X_train_files) > 0, \"‚ö†Ô∏è No training images found!\"\n",
    "assert len(X_train_files) == len(Y_train_files), \"‚ö†Ô∏è Mismatch in train images/masks!\"\n",
    "assert len(X_val_files) == len(Y_val_files), \"‚ö†Ô∏è Mismatch in val images/masks!\"\n",
    "\n",
    "# ƒê√°nh gi√° dataset size\n",
    "total_images = len(X_train_files) + len(X_val_files)\n",
    "if total_images >= 150:\n",
    "    print(\"\\n‚úÖ Dataset size EXCELLENT! Expected AP > 0.85\")\n",
    "elif total_images >= 100:\n",
    "    print(\"\\n‚úÖ Dataset size GOOD! Expected AP 0.75-0.85\")\n",
    "elif total_images >= 50:\n",
    "    print(\"\\n‚ö†Ô∏è Dataset size OK. Expected AP 0.65-0.75\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dataset size SMALL! Expected AP < 0.70\")\n",
    "    print(\"   Recommendation: Annotate more images (target: 150-200)\")\n",
    "\n",
    "# Load images\n",
    "print(\"\\nüì• Loading images...\")\n",
    "X_train = [np.array(Image.open(f)) for f in tqdm(X_train_files, desc=\"Train images\")]\n",
    "Y_train = [np.array(Image.open(f)) for f in tqdm(Y_train_files, desc=\"Train masks\")]\n",
    "X_val = [np.array(Image.open(f)) for f in tqdm(X_val_files, desc=\"Val images\")]\n",
    "Y_val = [np.array(Image.open(f)) for f in tqdm(Y_val_files, desc=\"Val masks\")]\n",
    "\n",
    "print(\"\\n‚úÖ Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f4385",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e6575a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m n_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_channel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m axis_norm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_channel = 1 if X_train[0].ndim == 2 else X_train[0].shape[-1]\n",
    "print(f\"Channels: {n_channel}\")\n",
    "\n",
    "axis_norm = (0,1)\n",
    "X_train = [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_train, desc=\"Normalize train\")]\n",
    "X_val = [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_val, desc=\"Normalize val\")]\n",
    "\n",
    "Y_train = [fill_label_holes(y) for y in tqdm(Y_train, desc=\"Fill holes train\")]\n",
    "Y_val = [fill_label_holes(y) for y in tqdm(Y_val, desc=\"Fill holes val\")]\n",
    "\n",
    "print(\"‚úÖ Preprocessing done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ad1ae",
   "metadata": {},
   "source": [
    "## 4. üî• AUGMENTATION C·∫¢I TI·∫æN - M·ªöI!\n",
    "\n",
    "**Thay ƒë·ªïi so v·ªõi version c≈©:**\n",
    "- ‚úÖ Th√™m **elastic deformation** (quan tr·ªçng cho cells!)\n",
    "- ‚úÖ Th√™m **brightness/contrast** augmentation\n",
    "- ‚úÖ TƒÉng **rotation** l√™n 360 ƒë·ªô\n",
    "- ‚úÖ Th√™m **Gaussian noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189ff459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Strong augmentation function created!\n",
      "\n",
      "üìä Augmentation details:\n",
      "   - Rotation: 0-360¬∞\n",
      "   - Flip: H + V\n",
      "   - Elastic: Œ±=30, œÉ=5\n",
      "   - Brightness: ¬±30%\n",
      "   - Contrast: ¬±20%\n",
      "   - Gaussian noise: œÉ=0.02\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "from skimage.transform import rotate\n",
    "\n",
    "def augmenter_strong(x, y):\n",
    "    \"\"\"\n",
    "    Augmentation m·∫°nh m·∫Ω cho StarDist\n",
    "    \n",
    "    √Åp d·ª•ng:\n",
    "    - Rotation: 0-360 ƒë·ªô\n",
    "    - Flip: horizontal/vertical\n",
    "    - Elastic deformation: bi·∫øn d·∫°ng ƒë√†n h·ªìi\n",
    "    - Brightness/Contrast: thay ƒë·ªïi ƒë·ªô s√°ng/t∆∞∆°ng ph·∫£n\n",
    "    - Gaussian noise: nhi·ªÖu Gaussian nh·∫π\n",
    "    \"\"\"\n",
    "    # 1. Random rotation (0-360 degrees)\n",
    "    if np.random.rand() > 0.5:\n",
    "        angle = np.random.uniform(0, 360)\n",
    "        x = rotate(x, angle, mode='reflect', preserve_range=True)\n",
    "        y = rotate(y, angle, order=0, mode='reflect', preserve_range=True).astype(y.dtype)\n",
    "    \n",
    "    # 2. Random flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.flip(x, axis=0)\n",
    "        y = np.flip(y, axis=0)\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.flip(x, axis=1)\n",
    "        y = np.flip(y, axis=1)\n",
    "    \n",
    "    # 3. Elastic deformation (quan tr·ªçng cho cells!)\n",
    "    if np.random.rand() > 0.5:\n",
    "        alpha = 30  # Strength of deformation\n",
    "        sigma = 5   # Smoothness of deformation\n",
    "        \n",
    "        shape = x.shape[:2]\n",
    "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "        \n",
    "        x_coords = np.arange(shape[0])[:, None] + dx\n",
    "        y_coords = np.arange(shape[1])[None, :] + dy\n",
    "        \n",
    "        indices = np.array([x_coords, y_coords])\n",
    "        \n",
    "        if x.ndim == 3:  # Color image\n",
    "            x = np.stack([map_coordinates(x[..., i], indices, order=1, mode='reflect') \n",
    "                          for i in range(x.shape[-1])], axis=-1)\n",
    "        else:  # Grayscale\n",
    "            x = map_coordinates(x, indices, order=1, mode='reflect')\n",
    "        \n",
    "        y = map_coordinates(y, indices, order=0, mode='reflect').astype(y.dtype)\n",
    "    \n",
    "    # 4. Brightness adjustment\n",
    "    if np.random.rand() > 0.5:\n",
    "        factor = np.random.uniform(0.7, 1.3)\n",
    "        x = np.clip(x * factor, 0, 1)\n",
    "    \n",
    "    # 5. Contrast adjustment\n",
    "    if np.random.rand() > 0.5:\n",
    "        factor = np.random.uniform(0.8, 1.2)\n",
    "        mean = x.mean()\n",
    "        x = np.clip((x - mean) * factor + mean, 0, 1)\n",
    "    \n",
    "    # 6. Gaussian noise\n",
    "    if np.random.rand() > 0.7:  # 30% chance\n",
    "        noise = np.random.normal(0, 0.02, x.shape)\n",
    "        x = np.clip(x + noise, 0, 1)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "print(\"‚úÖ Strong augmentation function created!\")\n",
    "print(\"\\nüìä Augmentation details:\")\n",
    "print(\"   - Rotation: 0-360¬∞\")\n",
    "print(\"   - Flip: H + V\")\n",
    "print(\"   - Elastic: Œ±=30, œÉ=5\")\n",
    "print(\"   - Brightness: ¬±30%\")\n",
    "print(\"   - Contrast: ¬±20%\")\n",
    "print(\"   - Gaussian noise: œÉ=0.02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52276e",
   "metadata": {},
   "source": [
    "## 5. Test Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9243319",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize augmentation examples\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m test_x \u001b[38;5;241m=\u001b[39m X_train[test_idx]\n\u001b[0;32m      4\u001b[0m test_y \u001b[38;5;241m=\u001b[39m Y_train[test_idx]\n\u001b[0;32m      6\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize augmentation examples\n",
    "test_idx = 0\n",
    "test_x = X_train[test_idx]\n",
    "test_y = Y_train[test_idx]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(test_x if test_x.ndim == 3 else test_x, cmap='gray' if test_x.ndim == 2 else None)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(test_y, cmap=lbl_cmap)\n",
    "axes[0, 1].set_title('Original Mask')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Augmented examples (5 examples filling remaining 10 slots)\n",
    "positions = [(0, 2), (0, 3), (1, 0), (1, 1), (1, 2), (1, 3), (2, 0), (2, 1), (2, 2), (2, 3)]\n",
    "\n",
    "for i in range(1, 6):\n",
    "    aug_x, aug_y = augmenter_strong(test_x.copy(), test_y.copy())\n",
    "    \n",
    "    # Get positions for image and mask\n",
    "    img_pos = positions[(i-1)*2]\n",
    "    mask_pos = positions[(i-1)*2 + 1]\n",
    "    \n",
    "    # Display augmented image\n",
    "    axes[img_pos].imshow(aug_x if aug_x.ndim == 3 else aug_x, cmap='gray' if aug_x.ndim == 2 else None)\n",
    "    axes[img_pos].set_title(f'Augmented {i}')\n",
    "    axes[img_pos].axis('off')\n",
    "    \n",
    "    # Display augmented mask\n",
    "    axes[mask_pos].imshow(aug_y, cmap=lbl_cmap)\n",
    "    axes[mask_pos].set_title(f'Augmented Mask {i}')\n",
    "    axes[mask_pos].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Augmentation looks good! Ready to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8befb",
   "metadata": {},
   "source": [
    "## 6. üîß CONFIG T·ªêI ∆ØU - C·∫¢I TI·∫æN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eac43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuring optimized model...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîß Configuring optimized model...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Dataset size analysis\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m n_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train)\n\u001b[0;32m      5\u001b[0m n_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_val)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Auto-adjust parameters based on dataset size\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"üîß Configuring optimized model...\\n\")\n",
    "\n",
    "# Dataset size analysis\n",
    "n_train = len(X_train)\n",
    "n_val = len(X_val)\n",
    "\n",
    "# Auto-adjust parameters based on dataset size\n",
    "if n_train >= 100:\n",
    "    train_epochs = 150\n",
    "    steps_per_epoch = 200\n",
    "    print(\"üìä Large dataset detected (‚â•100 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "elif n_train >= 50:\n",
    "    train_epochs = 200\n",
    "    steps_per_epoch = 150\n",
    "    print(\"üìä Medium dataset detected (50-100 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "else:\n",
    "    train_epochs = 250\n",
    "    steps_per_epoch = 100\n",
    "    print(\"üìä Small dataset detected (<50 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "    print(\"   ‚ö†Ô∏è Consider annotating more data for better results!\")\n",
    "\n",
    "# Model configuration\n",
    "img_size = X_train[0].shape[:2]\n",
    "train_patch_size = (256, 256) if min(img_size) < 512 else (512, 512)\n",
    "\n",
    "print(f\"\\nüéØ Model configuration:\")\n",
    "print(f\"   Image size: {img_size}\")\n",
    "print(f\"   Patch size: {train_patch_size}\")\n",
    "print(f\"   Channels: {n_channel}\")\n",
    "\n",
    "conf = Config2D(\n",
    "    n_rays=64,                      # Ph√π h·ª£p cho cells ph·ª©c t·∫°p\n",
    "    grid=(2, 2),                    # C√¢n b·∫±ng t·ªëc ƒë·ªô/ch√≠nh x√°c\n",
    "    use_gpu=False,                  # Python 3.13 compatibility\n",
    "    n_channel_in=n_channel,\n",
    "    train_patch_size=train_patch_size,\n",
    "    \n",
    "    # Training parameters - OPTIMIZED!\n",
    "    train_epochs=train_epochs,\n",
    "    train_steps_per_epoch=steps_per_epoch,\n",
    "    train_learning_rate=0.0003,     # Conservative learning rate\n",
    "    train_batch_size=4,             # Batch size 4 works well\n",
    "    train_reduce_lr={'factor': 0.5, 'patience': 10},  # Learning rate reduction\n",
    "    \n",
    "    # Regularization - M·ªöI!\n",
    "    train_background_reg=0.0001,    # Background regularization\n",
    "    train_foreground_only=0.9,      # Focus on foreground\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration created!\")\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac71d60",
   "metadata": {},
   "source": [
    "## 7. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec90e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: stardist_my_data_v2_improved...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StarDist2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_basedir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m StarDist2D(conf, name\u001b[38;5;241m=\u001b[39mmodel_name, basedir\u001b[38;5;241m=\u001b[39mmodel_basedir)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m created!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_basedir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StarDist2D' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'stardist_my_data_v2_improved'\n",
    "model_basedir = 'models'\n",
    "\n",
    "print(f\"Creating model: {model_name}...\")\n",
    "model = StarDist2D(conf, name=model_name, basedir=model_basedir)\n",
    "\n",
    "print(f\"\\n‚úÖ Model '{model_name}' created!\")\n",
    "print(f\"   Location: {model_basedir}/{model_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096ff4d",
   "metadata": {},
   "source": [
    "## 8. üöÄ TRAINING!\n",
    "\n",
    "**Expected training time:**\n",
    "- With GPU: 30-60 minutes\n",
    "- Without GPU: 2-4 hours\n",
    "\n",
    "**Expected results:**\n",
    "- 150+ images: AP > 0.85\n",
    "- 100-150 images: AP 0.75-0.85\n",
    "- 50-100 images: AP 0.65-0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f406b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ STARTING TRAINING WITH STRONG AUGMENTATION\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ STARTING TRAINING WITH STRONG AUGMENTATION\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚öôÔ∏è Config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs √ó \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps_per_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müé® Augmentation: Strong (rotation+flip+elastic+brightness+contrast+noise)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üöÄ STARTING TRAINING WITH STRONG AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Dataset: {n_train} train, {n_val} val\")\n",
    "print(f\"‚öôÔ∏è Config: {train_epochs} epochs √ó {steps_per_epoch} steps\")\n",
    "print(f\"üé® Augmentation: Strong (rotation+flip+elastic+brightness+contrast+noise)\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated time: {'30-60 min' if tf.config.list_physical_devices('GPU') else '2-4 hours'}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Training!\n",
    "history = model.train(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    augmenter=augmenter_strong,  # üî• Using strong augmentation!\n",
    "    epochs=conf.train_epochs,\n",
    "    steps_per_epoch=conf.train_steps_per_epoch,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e6a59",
   "metadata": {},
   "source": [
    "## 9. Optimize Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Optimizing thresholds...\\n\")\n",
    "\n",
    "model.optimize_thresholds(X_val, Y_val)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimized thresholds:\")\n",
    "print(f\"   prob_thresh = {model.thresholds.prob:.3f}\")\n",
    "print(f\"   nms_thresh = {model.thresholds.nms:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a039b",
   "metadata": {},
   "source": [
    "## 10. üìä EVALUATION\n",
    "\n",
    "**AP (Average Precision) targets:**\n",
    "- ‚≠ê‚≠ê‚≠ê Excellent: AP > 0.85\n",
    "- ‚≠ê‚≠ê Very Good: AP 0.75-0.85\n",
    "- ‚≠ê Good: AP 0.65-0.75\n",
    "- ‚ö†Ô∏è Needs improvement: AP < 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä EVALUATING MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict on validation set\n",
    "print(\"\\nPredicting on validation set...\")\n",
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val, desc=\"Predicting\")]\n",
    "\n",
    "# Compute metrics\n",
    "print(\"\\nComputing metrics...\")\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=True) \n",
    "         for t in tqdm([0.5, 0.6, 0.7, 0.8, 0.9], desc=\"Computing metrics\")]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for i, (thresh, stat) in enumerate(zip([0.5, 0.6, 0.7, 0.8, 0.9], stats)):\n",
    "    print(f\"IoU {thresh}: AP = {stat.mean_matched_score:.3f}\")\n",
    "\n",
    "ap_50 = stats[0].mean_matched_score\n",
    "print(f\"\\nüéØ OVERALL SCORE (AP@0.5): {ap_50:.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Performance assessment\n",
    "if ap_50 >= 0.85:\n",
    "    print(\"\\nüéâüéâüéâ EXCELLENT! AP ‚â• 0.85\")\n",
    "    print(\"‚úÖ Model is ready for production!\")\n",
    "    print(\"‚úÖ You can now run predictions on all 800 frames!\")\n",
    "elif ap_50 >= 0.75:\n",
    "    print(\"\\n‚úÖ‚úÖ VERY GOOD! AP 0.75-0.85\")\n",
    "    print(\"‚úÖ Model performance is strong.\")\n",
    "    print(\"üí° To reach >0.85: Consider adding 20-30 more diverse training images.\")\n",
    "elif ap_50 >= 0.65:\n",
    "    print(\"\\n‚úÖ GOOD! AP 0.65-0.75\")\n",
    "    print(\"‚ö†Ô∏è Model is acceptable but can be improved.\")\n",
    "    print(\"üí° Recommendations:\")\n",
    "    print(\"   1. Add 50-100 more training images\")\n",
    "    print(\"   2. Focus on challenging cases (overlapping cells, low contrast)\")\n",
    "    print(\"   3. Consider increasing n_rays to 96\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è NEEDS IMPROVEMENT! AP < 0.65\")\n",
    "    print(\"üí° Critical actions needed:\")\n",
    "    print(\"   1. ‚úÖ CHECK: Are your annotations correct?\")\n",
    "    print(\"   2. ‚úÖ ADD: At least 100+ more training images\")\n",
    "    print(\"   3. ‚úÖ DIVERSIFY: Include various lighting, densities, angles\")\n",
    "    print(\"   4. ‚úÖ TRY: Increase n_rays to 96 or grid to (1,1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ba4b0",
   "metadata": {},
   "source": [
    "## 11. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions on random samples\n",
    "n_samples = min(6, len(X_val))\n",
    "sample_indices = np.random.choice(len(X_val), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
    "if n_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img = X_val[idx]\n",
    "    mask_true = Y_val[idx]\n",
    "    mask_pred = Y_val_pred[idx]\n",
    "    \n",
    "    # Image\n",
    "    axes[i, 0].imshow(img if img.ndim == 3 else img, cmap='gray' if img.ndim == 2 else None)\n",
    "    axes[i, 0].set_title(f\"Image {idx}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask_true, cmap=lbl_cmap)\n",
    "    n_true = len(np.unique(mask_true)) - 1\n",
    "    axes[i, 1].set_title(f\"Ground Truth ({n_true} cells)\")\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(mask_pred, cmap=lbl_cmap)\n",
    "    n_pred = len(np.unique(mask_pred)) - 1\n",
    "    axes[i, 2].set_title(f\"Prediction ({n_pred} cells)\")\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    from stardist.plot import render_label\n",
    "    overlay = render_label(mask_pred, img=img if img.ndim == 3 else np.stack([img]*3, axis=-1), alpha=0.3)\n",
    "    axes[i, 3].imshow(overlay)\n",
    "    axes[i, 3].set_title(f\"Overlay\")\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_basedir}/{model_name}/validation_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Visualization saved to: {model_basedir}/{model_name}/validation_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc34d1",
   "metadata": {},
   "source": [
    "## 12. Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8767ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "if 'lr' in history.history:\n",
    "    ax2.plot(history.history['lr'], linewidth=2, color='green')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_basedir}/{model_name}/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training history saved to: {model_basedir}/{model_name}/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be84c69",
   "metadata": {},
   "source": [
    "## 13. Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training summary\n",
    "summary = f\"\"\"\n",
    "{'='*60}\n",
    "TRAINING SUMMARY - {model_name}\n",
    "{'='*60}\n",
    "\n",
    "üìä DATASET:\n",
    "   Training images: {n_train}\n",
    "   Validation images: {n_val}\n",
    "   Total images: {n_train + n_val}\n",
    "\n",
    "‚öôÔ∏è CONFIGURATION:\n",
    "   n_rays: {conf.n_rays}\n",
    "   grid: {conf.grid}\n",
    "   patch_size: {conf.train_patch_size}\n",
    "   epochs: {conf.train_epochs}\n",
    "   steps_per_epoch: {conf.train_steps_per_epoch}\n",
    "   batch_size: {conf.train_batch_size}\n",
    "   learning_rate: {conf.train_learning_rate}\n",
    "\n",
    "üé® AUGMENTATION:\n",
    "   Type: Strong (rotation+flip+elastic+brightness+contrast+noise)\n",
    "   Rotation: 0-360¬∞\n",
    "   Elastic: Œ±=30, œÉ=5\n",
    "   Brightness: ¬±30%\n",
    "   Contrast: ¬±20%\n",
    "\n",
    "üìà RESULTS:\n",
    "   AP@0.5: {ap_50:.3f}\n",
    "   AP@0.6: {stats[1].mean_matched_score:.3f}\n",
    "   AP@0.7: {stats[2].mean_matched_score:.3f}\n",
    "   AP@0.8: {stats[3].mean_matched_score:.3f}\n",
    "   AP@0.9: {stats[4].mean_matched_score:.3f}\n",
    "\n",
    "üéØ PERFORMANCE:\n",
    "   {'‚≠ê‚≠ê‚≠ê EXCELLENT!' if ap_50 >= 0.85 else '‚≠ê‚≠ê VERY GOOD!' if ap_50 >= 0.75 else '‚≠ê GOOD' if ap_50 >= 0.65 else '‚ö†Ô∏è NEEDS IMPROVEMENT'}\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save to file\n",
    "with open(f'{model_basedir}/{model_name}/training_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\n‚úÖ Summary saved to: {model_basedir}/{model_name}/training_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf1243",
   "metadata": {},
   "source": [
    "## üéØ NEXT STEPS\n",
    "\n",
    "### If AP ‚â• 0.85 (Excellent!):\n",
    "1. ‚úÖ **Ready for production!**\n",
    "2. Run `2_prediction_my_data.ipynb` to predict on all 800 frames\n",
    "3. Export results for analysis\n",
    "\n",
    "### If AP 0.75-0.85 (Very Good):\n",
    "1. Model is strong, but can be improved\n",
    "2. **Optional**: Add 20-30 more diverse training images\n",
    "3. Focus on difficult cases (overlapping cells, low contrast)\n",
    "4. Re-train with updated dataset\n",
    "\n",
    "### If AP 0.65-0.75 (Good):\n",
    "1. Model is acceptable but needs improvement\n",
    "2. **Recommended**: Add 50-100 more training images\n",
    "3. Ensure diversity in training data\n",
    "4. Consider increasing `n_rays` to 96\n",
    "5. Re-train\n",
    "\n",
    "### If AP < 0.65 (Needs Improvement):\n",
    "1. **Critical**: Check annotation quality\n",
    "2. **Must**: Add at least 100+ more training images\n",
    "3. Diversify dataset (lighting, density, angles)\n",
    "4. Try `n_rays=96` or `grid=(1,1)`\n",
    "5. Re-train and re-evaluate\n",
    "\n",
    "---\n",
    "\n",
    "## üìù ITERATION WORKFLOW:\n",
    "\n",
    "```\n",
    "1. Train ‚Üí 2. Evaluate ‚Üí 3. Analyze errors ‚Üí 4. Add/fix data ‚Üí 5. Re-train\n",
    "```\n",
    "\n",
    "**Remember**: More high-quality annotations = Better model performance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
