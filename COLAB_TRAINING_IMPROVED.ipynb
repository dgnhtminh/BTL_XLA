{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bde920e",
   "metadata": {},
   "source": [
    "## 0. C√†i ƒë·∫∑t v√† Setup m√¥i tr∆∞·ªùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fccdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G·ª° b·ªè phi√™n b·∫£n hi·ªán t·∫°i ƒë·ªÉ tr√°nh l·ªói\n",
    "!pip uninstall -y numpy opencv-python opencv-python-headless stardist csbdeep\n",
    "\n",
    "# C√†i ƒë·∫∑t phi√™n b·∫£n t∆∞∆°ng th√≠ch (NumPy 1.x cho Colab)\n",
    "!pip install \"numpy<2.0.0\" \"opencv-python-headless<4.10\"\n",
    "!pip install stardist csbdeep\n",
    "\n",
    "print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong. VUI L√íNG KH·ªûI ƒê·ªòNG L·∫†I RUNTIME!\")\n",
    "print(\"   Runtime > Restart runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch cho Python 3.12 compatibility\n",
    "import configparser\n",
    "\n",
    "if not hasattr(configparser, 'SafeConfigParser'):\n",
    "    configparser.SafeConfigParser = configparser.ConfigParser\n",
    "    print(\"‚úÖ ƒê√£ v√° l·ªói SafeConfigParser th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab1830",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive v√† Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57055977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c l√†m vi·ªác\n",
    "work_dir = '/content/stardist_project'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef94561",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset\n",
    "\n",
    "**C√ÅCH 1: Upload t·ª´ m√°y t√≠nh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"üì§ Ch·ªçn file my_dataset.zip ƒë·ªÉ upload\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Gi·∫£i n√©n\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"‚úÖ Extracted!\")\n",
    "\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b05353",
   "metadata": {},
   "source": [
    "**C√ÅCH 2: Copy t·ª´ Google Drive (KHUY·∫æN NGH·ªä)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54965abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n file tr√™n Google Drive\n",
    "drive_dataset_path = '/content/drive/MyDrive/my_dataset.rar'\n",
    "local_filename = 'my_dataset.rar'\n",
    "\n",
    "if os.path.exists(drive_dataset_path):\n",
    "    print(\"Copying from Google Drive...\")\n",
    "    shutil.copy2(drive_dataset_path, local_filename)\n",
    "    \n",
    "    # C√†i unrar v√† gi·∫£i n√©n\n",
    "    !apt-get install unrar -qq\n",
    "    print(\"Extracting RAR file...\")\n",
    "    \n",
    "    result = subprocess.run(['unrar', 'x', '-y', local_filename],\n",
    "                            capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Dataset copied and extracted successfully!\")\n",
    "    else:\n",
    "        print(\"‚ùå L·ªói khi gi·∫£i n√©n:\", result.stderr)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file t·∫°i: {drive_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aafae8",
   "metadata": {},
   "source": [
    "## 3. Import Libraries v√† Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be402b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"\\nüöÄ GPU detected! Training will be FAST.\")\n",
    "    use_gpu = True\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No GPU! H√£y b·∫≠t GPU: Runtime > Change runtime type > GPU\")\n",
    "    use_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6015c0d",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('my_dataset')\n",
    "\n",
    "X_train_files = sorted(glob(str(data_dir / 'train' / 'images' / '*')))\n",
    "Y_train_files = sorted(glob(str(data_dir / 'train' / 'masks' / '*')))\n",
    "X_val_files = sorted(glob(str(data_dir / 'val' / 'images' / '*')))\n",
    "Y_val_files = sorted(glob(str(data_dir / 'val' / 'masks' / '*')))\n",
    "\n",
    "print(f\"üìä Dataset size:\")\n",
    "print(f\"   Training: {len(X_train_files)} images\")\n",
    "print(f\"   Validation: {len(X_val_files)} images\")\n",
    "print(f\"   Total: {len(X_train_files) + len(X_val_files)} images\")\n",
    "\n",
    "# Ki·ªÉm tra\n",
    "assert len(X_train_files) > 0, \"‚ö†Ô∏è No training images found!\"\n",
    "assert len(X_train_files) == len(Y_train_files), \"‚ö†Ô∏è Mismatch in train images/masks!\"\n",
    "assert len(X_val_files) == len(Y_val_files), \"‚ö†Ô∏è Mismatch in val images/masks!\"\n",
    "\n",
    "# ƒê√°nh gi√° dataset size\n",
    "total_images = len(X_train_files) + len(X_val_files)\n",
    "if total_images >= 150:\n",
    "    print(\"\\n‚úÖ Dataset size EXCELLENT! Expected AP > 0.85\")\n",
    "elif total_images >= 100:\n",
    "    print(\"\\n‚úÖ Dataset size GOOD! Expected AP 0.75-0.85\")\n",
    "elif total_images >= 50:\n",
    "    print(\"\\n‚ö†Ô∏è Dataset size OK. Expected AP 0.65-0.75\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dataset size SMALL! Expected AP < 0.70\")\n",
    "\n",
    "# Load images\n",
    "print(\"\\nüì• Loading images...\")\n",
    "X_train = [np.array(Image.open(f)) for f in tqdm(X_train_files, desc=\"Train images\")]\n",
    "Y_train = [np.array(Image.open(f)) for f in tqdm(Y_train_files, desc=\"Train masks\")]\n",
    "X_val = [np.array(Image.open(f)) for f in tqdm(X_val_files, desc=\"Val images\")]\n",
    "Y_val = [np.array(Image.open(f)) for f in tqdm(Y_val_files, desc=\"Val masks\")]\n",
    "\n",
    "print(\"\\n‚úÖ Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08881704",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a186274",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 1 if X_train[0].ndim == 2 else X_train[0].shape[-1]\n",
    "print(f\"Channels: {n_channel}\")\n",
    "\n",
    "axis_norm = (0,1)\n",
    "X_train = [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_train, desc=\"Normalize train\")]\n",
    "X_val = [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_val, desc=\"Normalize val\")]\n",
    "\n",
    "Y_train = [fill_label_holes(y) for y in tqdm(Y_train, desc=\"Fill holes train\")]\n",
    "Y_val = [fill_label_holes(y) for y in tqdm(Y_val, desc=\"Fill holes val\")]\n",
    "\n",
    "print(\"‚úÖ Preprocessing done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777138af",
   "metadata": {},
   "source": [
    "## 6. üî• STRONG AUGMENTATION - C·∫¢I TI·∫æN!\n",
    "\n",
    "**C√°c k·ªπ thu·∫≠t augmentation:**\n",
    "- Rotation: 0-360¬∞\n",
    "- Flip: horizontal + vertical\n",
    "- Elastic deformation: bi·∫øn d·∫°ng ƒë√†n h·ªìi (quan tr·ªçng cho cells!)\n",
    "- Brightness: ¬±30%\n",
    "- Contrast: ¬±20%\n",
    "- Gaussian noise: nhi·ªÖu nh·∫π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1946869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "from skimage.transform import rotate\n",
    "\n",
    "def augmenter_strong(x, y):\n",
    "    \"\"\"\n",
    "    Strong augmentation for StarDist training\n",
    "    \"\"\"\n",
    "    # 1. Random rotation (0-360 degrees)\n",
    "    if np.random.rand() > 0.5:\n",
    "        angle = np.random.uniform(0, 360)\n",
    "        x = rotate(x, angle, mode='reflect', preserve_range=True)\n",
    "        y = rotate(y, angle, order=0, mode='reflect', preserve_range=True).astype(y.dtype)\n",
    "    \n",
    "    # 2. Random flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.flip(x, axis=0)\n",
    "        y = np.flip(y, axis=0)\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.flip(x, axis=1)\n",
    "        y = np.flip(y, axis=1)\n",
    "    \n",
    "    # 3. Elastic deformation\n",
    "    if np.random.rand() > 0.5:\n",
    "        alpha = 30\n",
    "        sigma = 5\n",
    "        \n",
    "        shape = x.shape[:2]\n",
    "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "        \n",
    "        x_coords = np.arange(shape[0])[:, None] + dx\n",
    "        y_coords = np.arange(shape[1])[None, :] + dy\n",
    "        \n",
    "        indices = np.array([x_coords, y_coords])\n",
    "        \n",
    "        if x.ndim == 3:\n",
    "            x = np.stack([map_coordinates(x[..., i], indices, order=1, mode='reflect') \n",
    "                          for i in range(x.shape[-1])], axis=-1)\n",
    "        else:\n",
    "            x = map_coordinates(x, indices, order=1, mode='reflect')\n",
    "        \n",
    "        y = map_coordinates(y, indices, order=0, mode='reflect').astype(y.dtype)\n",
    "    \n",
    "    # 4. Brightness adjustment\n",
    "    if np.random.rand() > 0.5:\n",
    "        factor = np.random.uniform(0.7, 1.3)\n",
    "        x = np.clip(x * factor, 0, 1)\n",
    "    \n",
    "    # 5. Contrast adjustment\n",
    "    if np.random.rand() > 0.5:\n",
    "        factor = np.random.uniform(0.8, 1.2)\n",
    "        mean = x.mean()\n",
    "        x = np.clip((x - mean) * factor + mean, 0, 1)\n",
    "    \n",
    "    # 6. Gaussian noise\n",
    "    if np.random.rand() > 0.7:\n",
    "        noise = np.random.normal(0, 0.02, x.shape)\n",
    "        x = np.clip(x + noise, 0, 1)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "print(\"‚úÖ Strong augmentation function created!\")\n",
    "print(\"\\nüìä Augmentation details:\")\n",
    "print(\"   - Rotation: 0-360¬∞\")\n",
    "print(\"   - Flip: H + V\")\n",
    "print(\"   - Elastic: Œ±=30, œÉ=5\")\n",
    "print(\"   - Brightness: ¬±30%\")\n",
    "print(\"   - Contrast: ¬±20%\")\n",
    "print(\"   - Gaussian noise: œÉ=0.02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae72591",
   "metadata": {},
   "source": [
    "## 7. Visualize Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11127c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 0\n",
    "test_x = X_train[test_idx]\n",
    "test_y = Y_train[test_idx]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(test_x if test_x.ndim == 3 else test_x, cmap='gray' if test_x.ndim == 2 else None)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(test_y, cmap=lbl_cmap)\n",
    "axes[0, 1].set_title('Original Mask')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Augmented examples\n",
    "for i in range(3):\n",
    "    aug_x, aug_y = augmenter_strong(test_x.copy(), test_y.copy())\n",
    "    \n",
    "    col = (i + 1) * 2 if i < 1 else i\n",
    "    row = 0 if i < 1 else 1\n",
    "    \n",
    "    axes[row, col].imshow(aug_x if aug_x.ndim == 3 else aug_x, cmap='gray' if aug_x.ndim == 2 else None)\n",
    "    axes[row, col].set_title(f'Augmented {i+1}')\n",
    "    axes[row, col].axis('off')\n",
    "    \n",
    "    axes[row, col+1].imshow(aug_y, cmap=lbl_cmap)\n",
    "    axes[row, col+1].set_title(f'Augmented Mask {i+1}')\n",
    "    axes[row, col+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Augmentation looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fbde8",
   "metadata": {},
   "source": [
    "## 8. üîß CONFIG T·ªêI ∆ØU - Auto-tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Configuring optimized model...\\n\")\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_val = len(X_val)\n",
    "\n",
    "# Auto-adjust parameters based on dataset size\n",
    "if n_train >= 100:\n",
    "    train_epochs = 150\n",
    "    steps_per_epoch = 200\n",
    "    print(\"üìä Large dataset detected (‚â•100 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "elif n_train >= 50:\n",
    "    train_epochs = 200\n",
    "    steps_per_epoch = 150\n",
    "    print(\"üìä Medium dataset detected (50-100 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "else:\n",
    "    train_epochs = 250\n",
    "    steps_per_epoch = 100\n",
    "    print(\"üìä Small dataset detected (<50 images)\")\n",
    "    print(f\"   ‚Üí epochs={train_epochs}, steps_per_epoch={steps_per_epoch}\")\n",
    "\n",
    "# Model configuration\n",
    "img_size = X_train[0].shape[:2]\n",
    "train_patch_size = (256, 256) if min(img_size) < 512 else (512, 512)\n",
    "\n",
    "print(f\"\\nüéØ Model configuration:\")\n",
    "print(f\"   Image size: {img_size}\")\n",
    "print(f\"   Patch size: {train_patch_size}\")\n",
    "print(f\"   Channels: {n_channel}\")\n",
    "print(f\"   GPU: {use_gpu}\")\n",
    "\n",
    "conf = Config2D(\n",
    "    n_rays=64,\n",
    "    grid=(2, 2),\n",
    "    use_gpu=use_gpu,\n",
    "    n_channel_in=n_channel,\n",
    "    train_patch_size=train_patch_size,\n",
    "    \n",
    "    # Training parameters - OPTIMIZED!\n",
    "    train_epochs=train_epochs,\n",
    "    train_steps_per_epoch=steps_per_epoch,\n",
    "    train_learning_rate=0.0003,\n",
    "    train_batch_size=4,\n",
    "    train_reduce_lr={'factor': 0.5, 'patience': 10},\n",
    "    \n",
    "    # Regularization\n",
    "    train_background_reg=0.0001,\n",
    "    train_foreground_only=0.9,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration created!\")\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43b82c",
   "metadata": {},
   "source": [
    "## 9. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'stardist_my_data_v2_improved'\n",
    "model_basedir = 'models'\n",
    "\n",
    "print(f\"Creating model: {model_name}...\")\n",
    "model = StarDist2D(conf, name=model_name, basedir=model_basedir)\n",
    "\n",
    "print(f\"\\n‚úÖ Model '{model_name}' created!\")\n",
    "print(f\"   Location: {model_basedir}/{model_name}/\")\n",
    "print(f\"   Total parameters: {model.keras_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1d757",
   "metadata": {},
   "source": [
    "## 10. üöÄ TRAINING!\n",
    "\n",
    "**Expected training time:**\n",
    "- With GPU: 30-60 minutes\n",
    "- Without GPU: 2-4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üöÄ STARTING TRAINING WITH STRONG AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Dataset: {n_train} train, {n_val} val\")\n",
    "print(f\"‚öôÔ∏è Config: {train_epochs} epochs √ó {steps_per_epoch} steps\")\n",
    "print(f\"üé® Augmentation: Strong (rotation+flip+elastic+brightness+contrast+noise)\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated time: {'30-60 min' if use_gpu else '2-4 hours'}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Training!\n",
    "history = model.train(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    augmenter=augmenter_strong,\n",
    "    epochs=conf.train_epochs,\n",
    "    steps_per_epoch=conf.train_steps_per_epoch,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4539477",
   "metadata": {},
   "source": [
    "## 11. Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5477584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "if 'lr' in history.history:\n",
    "    ax2.plot(history.history['lr'], linewidth=2, color='green')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_basedir}/{model_name}/training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "best_val_loss = min(history.history['val_loss'])\n",
    "print(f\"Best epoch: {best_epoch}/{len(history.history['val_loss'])}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b993cb7",
   "metadata": {},
   "source": [
    "## 12. Optimize Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6182a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Optimizing thresholds...\\n\")\n",
    "\n",
    "model.optimize_thresholds(X_val, Y_val)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimized thresholds:\")\n",
    "print(f\"   prob_thresh = {model.thresholds.prob:.3f}\")\n",
    "print(f\"   nms_thresh = {model.thresholds.nms:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e5eda",
   "metadata": {},
   "source": [
    "## 13. üìä EVALUATION\n",
    "\n",
    "**AP (Average Precision) targets:**\n",
    "- ‚≠ê‚≠ê‚≠ê Excellent: AP > 0.85\n",
    "- ‚≠ê‚≠ê Very Good: AP 0.75-0.85\n",
    "- ‚≠ê Good: AP 0.65-0.75\n",
    "- ‚ö†Ô∏è Needs improvement: AP < 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä EVALUATING MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict on validation set\n",
    "print(\"\\nPredicting on validation set...\")\n",
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val, desc=\"Predicting\")]\n",
    "\n",
    "# Compute metrics\n",
    "print(\"\\nComputing metrics...\")\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=True) \n",
    "         for t in tqdm([0.5, 0.6, 0.7, 0.8, 0.9], desc=\"Computing metrics\")]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for i, (thresh, stat) in enumerate(zip([0.5, 0.6, 0.7, 0.8, 0.9], stats)):\n",
    "    print(f\"IoU {thresh}: AP = {stat.mean_matched_score:.3f}\")\n",
    "\n",
    "ap_50 = stats[0].mean_matched_score\n",
    "print(f\"\\nüéØ OVERALL SCORE (AP@0.5): {ap_50:.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Performance assessment\n",
    "if ap_50 >= 0.85:\n",
    "    print(\"\\nüéâüéâüéâ EXCELLENT! AP ‚â• 0.85\")\n",
    "    print(\"‚úÖ Model is ready for production!\")\n",
    "elif ap_50 >= 0.75:\n",
    "    print(\"\\n‚úÖ‚úÖ VERY GOOD! AP 0.75-0.85\")\n",
    "    print(\"‚úÖ Model performance is strong.\")\n",
    "elif ap_50 >= 0.65:\n",
    "    print(\"\\n‚úÖ GOOD! AP 0.65-0.75\")\n",
    "    print(\"‚ö†Ô∏è Model is acceptable but can be improved.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è NEEDS IMPROVEMENT! AP < 0.65\")\n",
    "    print(\"üí° Consider adding more training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88111e60",
   "metadata": {},
   "source": [
    "## 14. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6991a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = min(4, len(X_val))\n",
    "sample_indices = np.random.choice(len(X_val), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
    "if n_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img = X_val[idx]\n",
    "    mask_true = Y_val[idx]\n",
    "    mask_pred = Y_val_pred[idx]\n",
    "    \n",
    "    # Image\n",
    "    axes[i, 0].imshow(img if img.ndim == 3 else img, cmap='gray' if img.ndim == 2 else None)\n",
    "    axes[i, 0].set_title(f\"Image {idx}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask_true, cmap=lbl_cmap)\n",
    "    n_true = len(np.unique(mask_true)) - 1\n",
    "    axes[i, 1].set_title(f\"Ground Truth ({n_true} objects)\")\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(mask_pred, cmap=lbl_cmap)\n",
    "    n_pred = len(np.unique(mask_pred)) - 1\n",
    "    axes[i, 2].set_title(f\"Prediction ({n_pred} objects)\")\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[i, 3].imshow(img if img.ndim == 3 else img, cmap='gray' if img.ndim == 2 else None)\n",
    "    axes[i, 3].imshow(mask_pred, cmap=lbl_cmap, alpha=0.5)\n",
    "    axes[i, 3].set_title(\"Overlay\")\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_basedir}/{model_name}/validation_results.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aab472",
   "metadata": {},
   "source": [
    "## 15. Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4bc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = f\"\"\"\n",
    "{'='*60}\n",
    "TRAINING SUMMARY - {model_name}\n",
    "{'='*60}\n",
    "\n",
    "üìä DATASET:\n",
    "   Training images: {n_train}\n",
    "   Validation images: {n_val}\n",
    "   Total images: {n_train + n_val}\n",
    "\n",
    "‚öôÔ∏è CONFIGURATION:\n",
    "   n_rays: {conf.n_rays}\n",
    "   grid: {conf.grid}\n",
    "   patch_size: {conf.train_patch_size}\n",
    "   epochs: {conf.train_epochs}\n",
    "   steps_per_epoch: {conf.train_steps_per_epoch}\n",
    "   batch_size: {conf.train_batch_size}\n",
    "   learning_rate: {conf.train_learning_rate}\n",
    "   GPU: {use_gpu}\n",
    "\n",
    "üé® AUGMENTATION:\n",
    "   Type: Strong (rotation+flip+elastic+brightness+contrast+noise)\n",
    "   Rotation: 0-360¬∞\n",
    "   Elastic: Œ±=30, œÉ=5\n",
    "   Brightness: ¬±30%\n",
    "   Contrast: ¬±20%\n",
    "\n",
    "üìà RESULTS:\n",
    "   AP@0.5: {ap_50:.3f}\n",
    "   AP@0.6: {stats[1].mean_matched_score:.3f}\n",
    "   AP@0.7: {stats[2].mean_matched_score:.3f}\n",
    "   AP@0.8: {stats[3].mean_matched_score:.3f}\n",
    "   AP@0.9: {stats[4].mean_matched_score:.3f}\n",
    "\n",
    "üéØ PERFORMANCE:\n",
    "   {'‚≠ê‚≠ê‚≠ê EXCELLENT!' if ap_50 >= 0.85 else '‚≠ê‚≠ê VERY GOOD!' if ap_50 >= 0.75 else '‚≠ê GOOD' if ap_50 >= 0.65 else '‚ö†Ô∏è NEEDS IMPROVEMENT'}\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save to file\n",
    "with open(f'{model_basedir}/{model_name}/training_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"‚úÖ Summary saved to: {model_basedir}/{model_name}/training_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c5530",
   "metadata": {},
   "source": [
    "## 16. Download Model v·ªÅ m√°y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20453231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# N√©n model th√†nh zip\n",
    "model_path = f\"{model_basedir}/{model_name}\"\n",
    "shutil.make_archive(f'{model_name}', 'zip', model_basedir, model_name)\n",
    "\n",
    "print(f\"‚úÖ Model ƒë√£ ƒë∆∞·ª£c n√©n: {model_name}.zip\")\n",
    "print(f\"\\nüì• Download file v·ªÅ m√°y:\")\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download(f'{model_name}.zip')\n",
    "\n",
    "print(\"\\nüíæ Gi·∫£i n√©n file .zip v√† copy th∆∞ m·ª•c v√†o models/ trong project c·ªßa b·∫°n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa2067",
   "metadata": {},
   "source": [
    "## 17. (Optional) L∆∞u v√†o Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7388197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model v√†o Google Drive ƒë·ªÉ l∆∞u tr·ªØ l√¢u d√†i\n",
    "drive_save_path = '/content/drive/MyDrive/stardist_models/'\n",
    "os.makedirs(drive_save_path, exist_ok=True)\n",
    "\n",
    "shutil.copy2(f'{model_name}.zip', drive_save_path)\n",
    "print(f\"‚úÖ Model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o Google Drive: {drive_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b0f4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ HO√ÄN TH√ÄNH!\n",
    "\n",
    "### C√°c b∆∞·ªõc ti·∫øp theo:\n",
    "\n",
    "1. **Download model v·ªÅ m√°y** (ƒë√£ n√©n th√†nh .zip)\n",
    "2. **Gi·∫£i n√©n** v√†o th∆∞ m·ª•c `models/` trong project\n",
    "3. **Ch·∫°y notebook** `2_prediction_my_data.ipynb` ƒë·ªÉ predict tr√™n all frames\n",
    "\n",
    "### Load model ƒë√£ train:\n",
    "\n",
    "```python\n",
    "from stardist.models import StarDist2D\n",
    "model = StarDist2D(None, name='stardist_my_data_v2_improved', basedir='models')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tips:**\n",
    "- N·∫øu AP < 0.85: Th√™m 20-50 ·∫£nh diverse v√†o training set\n",
    "- Focus v√†o c√°c cases kh√≥: overlapping cells, low contrast\n",
    "- Re-train v·ªõi dataset m·ªõi ƒë·ªÉ improve performance\n",
    "\n",
    "**Remember**: More high-quality annotations = Better model performance! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
