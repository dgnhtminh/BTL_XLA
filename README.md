# ğŸ”¬ Cell Detection & Segmentation using StarDist

Dá»± Ã¡n phÃ¡t hiá»‡n vÃ  phÃ¢n Ä‘oáº¡n táº¿ bÃ o tá»± Ä‘á»™ng tá»« áº£nh kÃ­nh hiá»ƒn vi sá»­ dá»¥ng deep learning model **StarDist**.

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)
- [CÃ¡c Ká»¹ Thuáº­t Xá»­ LÃ½ áº¢nh](#-cÃ¡c-ká»¹-thuáº­t-xá»­-lÃ½-áº£nh-Ä‘Æ°á»£c-Ã¡p-dá»¥ng)
- [TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng)
- [Cáº¥u trÃºc thÆ° má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#-sá»­-dá»¥ng)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [TÃ i liá»‡u tham kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

## ğŸ¯ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y thá»±c hiá»‡n **instance segmentation** cho táº¿ bÃ o trong áº£nh kÃ­nh hiá»ƒn vi, giÃºp:
- Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  Ä‘áº¿m sá»‘ lÆ°á»£ng táº¿ bÃ o
- PhÃ¢n Ä‘oáº¡n chÃ­nh xÃ¡c tá»«ng táº¿ bÃ o riÃªng láº»
- Xá»­ lÃ½ trÆ°á»ng há»£p táº¿ bÃ o chá»“ng láº¥p nhau

**CÃ´ng nghá»‡ sá»­ dá»¥ng:**
- **StarDist 2D**: MÃ´ hÃ¬nh deep learning dá»±a trÃªn star-convex polygons
- **TensorFlow/Keras**: Framework training model
- **Data Augmentation**: TÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘a dáº¡ng (rotation, flip, elastic, brightness, contrast)

## ğŸ–¼ï¸ CÃ¡c Ká»¹ Thuáº­t Xá»­ LÃ½ áº¢nh ÄÆ°á»£c Ãp Dá»¥ng

Dá»± Ã¡n nÃ y tÃ­ch há»£p nhiá»u ká»¹ thuáº­t xá»­ lÃ½ áº£nh quan trá»ng trong Computer Vision vÃ  Image Processing:

### 1. **Tiá»n xá»­ lÃ½ áº£nh (Image Preprocessing)**

#### Percentile-based Normalization
- **Má»¥c Ä‘Ã­ch**: Chuáº©n hÃ³a cÆ°á»ng Ä‘á»™ sÃ¡ng, loáº¡i bá» outliers
- **PhÆ°Æ¡ng phÃ¡p**: Sá»­ dá»¥ng percentile 1% vÃ  99.8% thay vÃ¬ min-max thÃ´ng thÆ°á»ng
- **CÃ´ng thá»©c**: `I_norm = (I - p1) / (p99.8 - p1)`
- **Lá»£i Ã­ch**: Robust vá»›i noise, tÄƒng contrast, Ä‘á»“ng nháº¥t giá»¯a cÃ¡c áº£nh
- **Ãp dá»¥ng**: Per-channel normalization cho áº£nh RGB (3 channels riÃªng biá»‡t)

```python
from csbdeep.utils import normalize
img_normalized = normalize(img, pmin=1, pmax=99.8, axis=(0,1))
```

### 2. **Data Augmentation - TÄƒng cÆ°á»ng dá»¯ liá»‡u**

#### 2.1 Geometric Transformations (Biáº¿n Ä‘á»•i hÃ¬nh há»c)

**Random Rotation (0-360Â°)**
- Xoay áº£nh ngáº«u nhiÃªn má»i gÃ³c Ä‘á»ƒ model khÃ´ng bias vá»›i orientation
- Ãp dá»¥ng cáº£ cho image vÃ  mask vá»›i interpolation phÃ¹ há»£p

**Random Flip (Horizontal + Vertical)**
- Láº­t áº£nh theo chiá»u ngang vÃ  dá»c
- TÄƒng gáº¥p 4 láº§n sá»‘ biáº¿n thá»ƒ tá»« 1 áº£nh gá»‘c

**Elastic Deformation (Biáº¿n dáº¡ng Ä‘Ã n há»“i)**
- MÃ´ phá»ng sá»± thay Ä‘á»•i hÃ¬nh dáº¡ng tá»± nhiÃªn cá»§a táº¿ bÃ o
- Sá»­ dá»¥ng Gaussian filter Ä‘á»ƒ táº¡o displacement field mÆ°á»£t mÃ 
- Parameters: Î± (amplitude) = 50, Ïƒ (smoothness) = 5
- Giá»¯ nguyÃªn topology cá»§a objects (váº«n star-convex)

```python
from scipy.ndimage import gaussian_filter, map_coordinates
dx = gaussian_filter(np.random.randn(*shape), sigma=5) * alpha
dy = gaussian_filter(np.random.randn(*shape), sigma=5) * alpha
```

#### 2.2 Intensity Transformations (Biáº¿n Ä‘á»•i cÆ°á»ng Ä‘á»™)

**Brightness Adjustment (Â±30%)**
- Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng tá»•ng thá»ƒ cá»§a áº£nh
- MÃ´ phá»ng thay Ä‘á»•i Ã¡nh sÃ¡ng giá»¯a cÃ¡c frames

**Contrast Adjustment (Â±20%)**
- Äiá»u chá»‰nh Ä‘á»™ tÆ°Æ¡ng pháº£n quanh giÃ¡ trá»‹ mean
- TÄƒng kháº£ nÄƒng phÃ¢n biá»‡t foreground/background

**Gaussian Noise Addition**
- ThÃªm nhiá»…u Gaussian vá»›i Ïƒ = 0.01
- GiÃºp model robust vá»›i sensor noise

### 3. **Patch-based Processing**

**Random Patch Extraction**
- Cáº¯t random patches 256Ã—256 tá»« áº£nh lá»›n hÆ¡n
- TÄƒng sá»‘ lÆ°á»£ng training samples
- Tiáº¿t kiá»‡m bá»™ nhá»› GPU, tÄƒng batch size

**Grid-based Inference**
- Chia áº£nh lá»›n thÃ nh grid tiles vá»›i overlap
- Merge predictions Ä‘á»ƒ trÃ¡nh artifacts á»Ÿ biÃªn
- Tá»± Ä‘á»™ng tÃ­nh toÃ¡n n_tiles tá»‘i Æ°u

### 4. **Instance Segmentation vá»›i Star-convex Polygons**

**Radial Distance Representation**
- Biá»ƒu diá»…n má»—i cell báº±ng 64 khoáº£ng cÃ¡ch xuyÃªn tÃ¢m (rays)
- Tá»« tÃ¢m cell Ä‘áº¿n boundary theo 64 hÆ°á»›ng Ä‘á»u nhau
- Hiá»‡u quáº£ hÆ¡n predict toÃ n bá»™ contour

**Object Probability Map**
- Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t má»—i pixel lÃ  tÃ¢m cá»§a cell
- Sá»­ dá»¥ng Binary Cross-Entropy vá»›i class balancing
- Focal loss Ä‘á»ƒ xá»­ lÃ½ imbalance giá»¯a foreground/background

### 5. **Post-processing**

**Non-Maximum Suppression (NMS)**
- Loáº¡i bá» detections trÃ¹ng láº·p dá»±a trÃªn IoU threshold
- Sáº¯p xáº¿p theo confidence score (probability)
- Threshold: prob_thresh = 0.5, nms_thresh = 0.4

**Polygon to Mask Conversion**
- Chuyá»ƒn Ä‘á»•i star-convex polygon thÃ nh binary mask
- Fill interior cá»§a polygon cho instance segmentation

### 6. **Feature Extraction vá»›i U-Net**

**U-Net Architecture**
- Encoder-decoder vá»›i skip connections
- 3 levels, 32 base filters, kernel size 3Ã—3
- Max pooling 2Ã—2 cho downsampling
- Transposed convolution cho upsampling
- Skip connections báº£o toÃ n spatial information

### 7. **Metrics vÃ  Evaluation**

**IoU-based Matching**
- TÃ­nh Intersection over Union giá»¯a predicted vÃ  ground truth
- Matching táº¡i nhiá»u ngÆ°á»¡ng IoU (0.5, 0.6, 0.7, 0.8, 0.9)

**Detection Metrics**
- Average Precision (AP): Diá»‡n tÃ­ch dÆ°á»›i PR curve
- Precision, Recall, F1-Score táº¡i tá»«ng ngÆ°á»¡ng
- Per-image vÃ  aggregate statistics

### 8. **Frame Selection Strategy**

**Temporal Diversity Sampling**
- Chá»n frames Ä‘á»u theo timeline (30%)
- Äáº£m báº£o coverage toÃ n bá»™ video

**Brightness-based Stratified Sampling**
- PhÃ¢n tÃ­ch histogram Ä‘á»™ sÃ¡ng
- Chia thÃ nh bins vÃ  chá»n Ä‘á»u tá»« má»—i bin (70%)
- TÄƒng diversity vá» lighting conditions

### TÃ³m táº¯t Impact

| Ká»¹ thuáº­t | Impact | Improvement |
|----------|---------|-------------|
| Percentile normalization | Loáº¡i bá» outliers, tÄƒng contrast | +15% stability |
| Strong augmentation | TÄƒng diversity, giáº£m overfitting | +10-15% AP |
| Patch-based training | TÄƒng samples, tiáº¿t kiá»‡m memory | 4Ã— training samples |
| Star-convex representation | Hiá»‡u quáº£ cho round objects | 5Ã— faster vs Mask R-CNN |
| U-Net + skip connections | Preserve spatial details | High-quality boundaries |
| Smart frame selection | Optimize annotation effort | 50-60% time saved |

**â†’ Káº¿t há»£p cÃ¡c ká»¹ thuáº­t nÃ y giÃºp Ä‘áº¡t AP@0.5 = 0.812 chá»‰ vá»›i 233 áº£nh training!**

## âœ¨ TÃ­nh nÄƒng

- ğŸ” **PhÃ¡t hiá»‡n táº¿ bÃ o**: Tá»± Ä‘á»™ng detect táº¥t cáº£ táº¿ bÃ o trong áº£nh
- ğŸ¨ **PhÃ¢n Ä‘oáº¡n chÃ­nh xÃ¡c**: Táº¡o mask riÃªng biá»‡t cho tá»«ng táº¿ bÃ o
- ğŸ“Š **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t**: TÃ­nh toÃ¡n metrics (AP, Precision, Recall, F1-score)
- ğŸ² **Chá»n frames thÃ´ng minh**: Lá»±a chá»n dá»¯ liá»‡u Ä‘a dáº¡ng cho annotation
- ğŸ“ˆ **Visualization**: Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n vá»›i overlay masks

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
stardist_project/
â”œâ”€â”€ 0_select_frames_for_annotation.py  # Script chá»n frames cho annotation
â”œâ”€â”€ 0_pre_label_frames.py              # Script tiá»n xá»­ lÃ½ labels
â”œâ”€â”€ 1_COLAB_TRAINING_IMPROVED.ipynb    # Notebook training model
â”œâ”€â”€ 2_prediction_with_metrics.ipynb    # Notebook inference vÃ  Ä‘Ã¡nh giÃ¡
â”œâ”€â”€ selected_frames_train.txt          # Danh sÃ¡ch frames training
â”œâ”€â”€ selected_frames_val.txt            # Danh sÃ¡ch frames validation
â”œâ”€â”€ frames/                            # ThÆ° má»¥c chá»©a frames gá»‘c
â”œâ”€â”€ my_dataset/                        # Dataset Ä‘Ã£ annotation
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/                    # 174 áº£nh training
â”‚   â”‚   â””â”€â”€ masks/                     # 174 masks training
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ images/                    # 59 áº£nh validation
â”‚       â””â”€â”€ masks/                     # 59 masks validation
â”œâ”€â”€ models/                            # ThÆ° má»¥c chá»©a trained models
â”‚   â””â”€â”€ stardist_my_data_v2_improved/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ weights_best.h5
â”‚       â”œâ”€â”€ thresholds.json
â”‚       â””â”€â”€ training_summary.txt
â”œâ”€â”€ predictions/                       # Káº¿t quáº£ dá»± Ä‘oÃ¡n
â”‚   â”œâ”€â”€ masks/                         # Predicted masks
â”‚   â”œâ”€â”€ overlays/                      # Visualization overlays
â”‚   â”œâ”€â”€ detection_metrics.csv         # Metrics tá»•ng há»£p
â”‚   â””â”€â”€ detailed_objects.csv          # Chi tiáº¿t tá»«ng object
â””â”€â”€ stardist/                         # Source code StarDist (modified)
```

## ğŸ”§ CÃ i Ä‘áº·t

### YÃªu cáº§u
- Python 3.7+
- TensorFlow 2.x
- CUDA (khuyáº¿n nghá»‹ cho training nhanh)

### CÃ i Ä‘áº·t thÆ° viá»‡n

```bash
pip install tensorflow
pip install stardist
pip install csbdeep
pip install numpy pandas matplotlib pillow scikit-image tqdm
```

Hoáº·c sá»­ dá»¥ng requirements.txt:

```bash
pip install -r requirements.txt
```

## ğŸš€ Sá»­ dá»¥ng

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u

**Chá»n frames cho annotation:**
```bash
python 0_select_frames_for_annotation.py
```

Script nÃ y sáº½:
- Chá»n 200 frames Ä‘a dáº¡ng tá»« 800 frames gá»‘c
- Chia thÃ nh 150 frames training + 50 frames validation
- Sá»­ dá»¥ng chiáº¿n lÆ°á»£c chá»n thÃ´ng minh (temporal + diversity)

### 2. Training model

Má»Ÿ vÃ  cháº¡y `1_COLAB_TRAINING_IMPROVED.ipynb`:
- Cáº¥u hÃ¬nh model vá»›i 64 rays, patch size 256x256
- Sá»­ dá»¥ng strong augmentation
- Training 150 epochs vá»›i early stopping
- LÆ°u best model vÃ o `models/`

**Cáº¥u hÃ¬nh training:**
- Batch size: 4
- Learning rate: 0.0003
- Steps per epoch: 200
- Augmentation: rotation + flip + elastic + brightness + contrast + noise

### 3. Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡

Má»Ÿ vÃ  cháº¡y `2_prediction_with_metrics.ipynb`:
- Load trained model
- Dá»± Ä‘oÃ¡n trÃªn validation set
- TÃ­nh toÃ¡n metrics (AP, Precision, Recall, F1)
- Export káº¿t quáº£ vÃ  visualization

## ğŸ“Š Káº¿t quáº£

### Hiá»‡u suáº¥t model

Model **stardist_my_data_v2_improved** Ä‘áº¡t Ä‘Æ°á»£c:

#### Average Precision (AP) táº¡i cÃ¡c ngÆ°á»¡ng IoU

| IoU Threshold | AP | Precision | Recall | F1-Score |
|--------------|-----|-----------|--------|----------|
| **0.5** | **0.812** | **0.869** | **0.833** | **0.850** |
| **0.6** | **0.820** | 0.843 | 0.808 | 0.826 |
| **0.7** | **0.836** | 0.767 | 0.735 | 0.751 |
| **0.8** | **0.863** | 0.564 | 0.540 | 0.552 |
| **0.9** | **0.917** | 0.091 | 0.087 | 0.089 |

**ÄÃ¡nh giÃ¡ tá»•ng quan**: â­â­ **VERY GOOD**

#### Giáº£i thÃ­ch metrics

- **Average Precision (AP)**: Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong Precision-Recall
- **Precision**: Tá»· lá»‡ cells Ä‘Æ°á»£c detect Ä‘Ãºng trong táº¥t cáº£ predictions
- **Recall**: Tá»· lá»‡ cells thá»±c táº¿ Ä‘Æ°á»£c model phÃ¡t hiá»‡n ra
- **F1-Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall

**Káº¿t quáº£ ná»•i báº­t:**
- ğŸ¯ **AP@0.5 = 0.812**: Model detect chÃ­nh xÃ¡c vá»›i IoU â‰¥ 50%
- ğŸ¯ **Precision@0.5 = 0.869**: 86.9% predictions lÃ  Ä‘Ãºng (Ã­t false positives)
- ğŸ¯ **Recall@0.5 = 0.833**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c 83.3% cells thá»±c táº¿ (Ã­t false negatives)
- ğŸ¯ **F1@0.5 = 0.850**: CÃ¢n báº±ng tá»‘t giá»¯a Precision vÃ  Recall

### Dataset

- **Training**: 174 áº£nh (tá»« 800 frames gá»‘c)
- **Validation**: 59 áº£nh
- **Total**: 233 áº£nh Ä‘Ã£ annotation
- **Selection strategy**: Temporal diversity (30%) + Brightness diversity (70%)

### Kháº£ nÄƒng cá»§a model

Model cÃ³ thá»ƒ:
- âœ… PhÃ¡t hiá»‡n chÃ­nh xÃ¡c táº¿ bÃ o vá»›i IoU â‰¥ 0.5
- âœ… PhÃ¢n biá»‡t táº¿ bÃ o chá»“ng láº¥p nhau
- âœ… Xá»­ lÃ½ tá»‘t biáº¿n Ä‘á»•i vá» Ä‘á»™ sÃ¡ng/tÆ°Æ¡ng pháº£n
- âœ… Segmentation chÃ­nh xÃ¡c biÃªn táº¿ bÃ o vá»›i star-convex polygons
- âœ… Robust vá»›i noise vÃ  artifacts trong áº£nh kÃ­nh hiá»ƒn vi

## ğŸ“– TÃ i liá»‡u tham kháº£o

### Papers
- [StarDist - Object Detection with Star-convex Shapes](https://arxiv.org/abs/1806.03535)
- [Cell Detection with Star-convex Polygons](https://arxiv.org/abs/2006.14109)
### Code & Documentation
- [StarDist GitHub](https://github.com/stardist/stardist)
- [StarDist Documentation](https://stardist.net/)

Dá»± Ã¡n Xá»­ lÃ½ áº¢nh - PhÃ¡t hiá»‡n vÃ  PhÃ¢n Ä‘oáº¡n Táº¿ bÃ o

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

---

â­ Náº¿u tháº¥y há»¯u Ã­ch, hÃ£y star repo nÃ y!
